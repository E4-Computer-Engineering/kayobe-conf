[client.libvirt]
admin socket = /var/run/ceph/$cluster-$type.$id.$pid.$cctid.asok # must be writable by QEMU and allowed by SELinux or AppArmor
log file = /var/log/ceph/qemu-guest-$pid.log # must be writable by QEMU and allowed by SELinux or AppArmor

[client.rgw.controll01.rgw0]
host = controll01
keyring = /var/lib/ceph/radosgw/ceph-rgw.controll01.rgw0/keyring
log file = /var/log/ceph/ceph-rgw-controll01.rgw0.log
rgw frontends = beast endpoint=100.64.2.150:8080
rgw thread pool size = 512

[client.rgw.controll01.rgw1]
host = controll01
keyring = /var/lib/ceph/radosgw/ceph-rgw.controll01.rgw1/keyring
log file = /var/log/ceph/ceph-rgw-controll01.rgw1.log
rgw frontends = beast endpoint=100.64.2.150:8081
rgw thread pool size = 512

[client.rgw.controll01.rgw2]
host = controll01
keyring = /var/lib/ceph/radosgw/ceph-rgw.controll01.rgw2/keyring
log file = /var/log/ceph/ceph-rgw-controll01.rgw2.log
rgw frontends = beast endpoint=100.64.2.150:8082
rgw thread pool size = 512

[client.rgw.controll01.rgw0]
nss db path = /var/lib/ceph/radosgw/ceph-radosgw.controll01/nss
rgw enable apis = s3,swift,swift_auth,admin
rgw keystone accepted admin roles = ResellerAdmin
rgw keystone accepted roles = Member, _member_, admin
rgw keystone admin domain = default
rgw keystone admin password = 0o5CmXpUcYlldwYJ3i5dGDNZNvNw2TZRNnH8UXAj
rgw keystone admin project = service
rgw keystone admin user = ceph_rgw
rgw keystone api version = 3
rgw keystone make new tenants = true
rgw keystone url = http://100.64.2.60:5000
rgw keystone verify ssl = false
rgw s3 auth use keystone = true
rgw swift account in url = true
rgw swift compatibility = false
rgw swift versioning enabled = true

# Please do not change this file directly since it is managed by Ansible and will be overwritten
[global]
cluster network = 100.127.103.0/24
fsid = 7bc33e25-1729-40fb-9246-b334ea4f9e02
mon host = [v2:100.127.103.100:3300,v1:100.127.103.100:6789],[v2:100.127.103.101:3300,v1:100.127.103.101:6789],[v2:100.127.103.102:3300,v1:100.127.103.102:6789]
mon initial members = controll01,controll02,controll03
mon_allow_pool_size_one = False
mon_warn_on_pool_no_redundancy = True
osd pool default crush rule = -1
osd_pool_default_min_size = 2
osd_pool_default_size = 3
public network = 100.127.103.0/24

[osd]
osd memory target = 54070136012

